# Introduction to Dynamic Programming

Dynamic Programming (DP) is a problem-solving technique that breaks down a complex problem into simpler, overlapping subproblems. The key idea is to solve each subproblem just once and store its result. When the same subproblem is encountered again, you simply look up the saved result instead of re-calculating it. Think of it as an optimized form of recursion that has a memory.

***

### ## Key Characteristics of a DP Problem

For a problem to be solvable with Dynamic Programming, it must have two main properties:

* **Optimal Substructure**: This means that the optimal solution to the overall problem can be constructed from the optimal solutions of its subproblems. For example, the shortest path to a destination is made up of the shortest paths to the cities along the way.
* **Overlapping Subproblems**: This means that the algorithm ends up needing to solve the exact same smaller problem multiple times. DP shines here by saving the result of a subproblem the first time it's solved, avoiding redundant work later on.

***

### ## The Two Approaches to Dynamic Programming

There are two main ways to implement a DP solution:

1.  **Memoization (Top-Down)** ðŸ§ 
    This approach feels like a standard recursive solution. You write a function that calls itself to solve smaller pieces of the problem. However, you add a "memo" (like a cache or a lookup table) to store the results. Before computing a solution, you check if it's already in the memo. If it is, you return the stored value; if not, you compute it, store it, and then return it.

2.  **Tabulation (Bottom-Up)** ðŸ“Š
    This approach solves the problem iteratively, starting with the smallest possible subproblems. You create a table (usually an array or a grid) and fill it out from the beginning. Each entry in the table represents the solution to a subproblem. You use the results of previous entries to calculate the next one until you've solved the original problem. This method avoids recursion altogether.

***

### ## When to Think of Using Dynamic Programming

You should consider DP when you encounter problems that involve:

* **Optimization**: Problems that ask for the **maximum** or **minimum** result, like finding the shortest path, the longest common subsequence, or the maximum value you can get in a knapsack.
* **Counting**: Problems that ask "how many ways?" can a certain outcome be achieved. A classic example is counting the number of ways to make change for a specific amount using a given set of coins.
* **Sequential Decisions**: Problems where you need to make a sequence of decisions to arrive at an optimal solution, often seen in resource allocation or game theory scenarios.