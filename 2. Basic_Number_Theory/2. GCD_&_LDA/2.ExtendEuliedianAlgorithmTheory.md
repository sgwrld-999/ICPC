## **1. Problem It Solves**

The **basic Euclidean Algorithm** finds:

$$
\text{gcd}(a, b)
$$

The **Extended Euclidean Algorithm** also finds integers $x$ and $y$ such that:

$$
a \cdot x + b \cdot y = \text{gcd}(a, b)
$$

This equation is called **Bézout’s Identity**.

---

## **2. Why This Is Useful in CP**

1. **Modular Inverse**
   If $\gcd(a, m) = 1$, EEA finds $x$ such that:

   $$
   a \cdot x \equiv 1 \ (\text{mod} \ m)
   $$

   → $x$ is the modular inverse.

2. **Solving Linear Diophantine Equations**
   Example: Solve $35x + 15y = 5$.

3. **Chinese Remainder Theorem**
   Needs modular inverses for merging congruences.

---

## **3. How It Extends Euclid’s Algorithm**

Euclid’s algorithm does:

```text
gcd(a, b) = gcd(b, a % b)
```

In EEA, while computing the GCD, we also **track coefficients** $x$ and $y$.

---

## **4. Recursive Logic**

If $b = 0$:

* $\gcd(a, 0) = a$
* $a \cdot 1 + 0 \cdot 0 = a$
  So $x = 1, y = 0$.

Otherwise:

1. Recursively solve:

   $$
   \gcd(b, a \bmod b) = b \cdot x_1 + (a \bmod b) \cdot y_1
   $$
2. Replace $a \bmod b$ with $a - \lfloor a/b \rfloor \cdot b$.
3. Rearrange to get new $x, y$.

---

## **5. Code**

```python
def extended_gcd(a, b):
    if b == 0:
        return a, 1, 0  # gcd, x, y
    gcd, x1, y1 = extended_gcd(b, a % b)
    x = y1
    y = x1 - (a // b) * y1
    return gcd, x, y
```

---

## **6. Example**

Find $x, y$ for $30x + 20y = \gcd(30, 20)$.

**Step-by-step:**

1. `extended_gcd(30, 20)`
2. Calls `extended_gcd(20, 10)`
3. Calls `extended_gcd(10, 0)` → returns `(10, 1, 0)`
4. Backtracking:

   * From `(20, 10)`:
     $x = 0$, $y = 1 - (20 // 10) \cdot 0 = 1$ → `(10, 0, 1)`
   * From `(30, 20)`:
     $x = 1$, $y = 0 - (30 // 20) \cdot 1 = -1$ → `(10, 1, -1)`

**Final:**

$$
30(1) + 20(-1) = 10
$$

---

## **7. Using for Modular Inverse**

If $a \cdot x + m \cdot y = 1$, then $x$ is the modular inverse of $a \ (\text{mod} \ m)$.

Example:

```python
def mod_inverse(a, m):
    gcd, x, _ = extended_gcd(a, m)
    if gcd != 1:
        return None
    return x % m
```

---

## **8. Complexity**

Same as Euclid’s:

$$
O(\log \min(a, b))
$$

with just a constant overhead.

---

Alright, let’s break this down so you can see why the **Extended Euclidean Algorithm (EEA)** is more than just a math curiosity and how it’s actually a workhorse in **code optimisation, DSA, and competitive programming**.

---

## **Quick Recap**

The **normal Euclidean algorithm** finds

$$
\gcd(a, b)
$$

The **extended version** also finds integers $x$ and $y$ such that:

$$
a \cdot x + b \cdot y = \gcd(a, b)
$$

These $x$ and $y$ are called **Bézout coefficients**.

---

## **Where It’s Used**

### **1. Modular Inverse (Very common in competitive programming)**

If $a$ and $m$ are coprime, the EEA can quickly find $a^{-1} \pmod{m}$.
Why care? Because:

* Modular inverses let you replace **division** in modular arithmetic with a **multiplication** (which is much faster and avoids floating-point headaches).
* Essential for modular combinatorics, cryptography, hashing, and number theory problems.

Example:

$$
\frac{A}{B} \mod M = A \cdot B^{-1} \mod M
$$

Finding $B^{-1}$ with EEA is $O(\log \min(a, b))$ — blazing fast.

---

### **2. Solving Linear Diophantine Equations**

Equations like:

$$
a \cdot x + b \cdot y = c
$$

If $c$ is divisible by $\gcd(a, b)$, EEA gives you **one** solution instantly, and then you can find all others.
This pops up in:

* Scheduling / resource allocation problems
* Number theory tasks
* Competitive programming constraints

---

### **3. Chinese Remainder Theorem (CRT)**

When moduli are not coprime, EEA can help merge congruences efficiently.
In competitive programming:

* Used for large integer computations without overflow.
* Critical in RSA cryptography, polynomial hashing, and modular systems.

---

### **4. Cryptography (RSA, ECC, etc.)**

EEA is used to compute:

* Private keys from public keys
* Modular inverses in huge integer ranges
  Its $O(\log n)$ complexity is a life-saver when numbers have hundreds of digits.

---

### **5. Code Optimisation**

* Replacing **naïve inverse computation** (like trying values until one works) with EEA slashes runtime from $O(m)$ to $O(\log m)$.
* This is the difference between **passing all test cases** and **timing out** in competitive programming.

---



Almost — you’ve got the right idea, but let’s make it sharper.

The **Extended Euclidean Algorithm (EEA)** tells us:

For two integers $a$ and $b$,

$$
\gcd(a, b) = a \cdot x + b \cdot y
$$

for some integers $x$ and $y$.

That means:

* $x$ and $y$ are **specific integers** the EEA finds.
* The equation $a \cdot x + b \cdot y = \gcd(a, b)$ **always has at least one solution** (in fact, infinitely many solutions).
* If you want $a \cdot x + b \cdot y = c$ for some other $c$, then it has integer solutions **only if** $c$ is a multiple of $\gcd(a, b)$.

So it’s not about a “line” in the geometric sense — it’s a **linear Diophantine equation** (integer solutions).

